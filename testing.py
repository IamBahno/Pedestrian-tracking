from datetime import datetime
import os
from concurrent.futures import ThreadPoolExecutor
import cv2
import numpy as np
import matplotlib.pyplot as plt
from ultralytics import YOLO


    
def test_model_on_datasets():
    """Test all models on both datasets and generate comparison graphs"""
    print("üß™ Testing models on datasets...")
    
    models = {
        "Model 1": "models/dataset1/weights/best.pt",
        "Model 2": "models/dataset2/weights/best.pt", 
        "Model 3": "models/combined/weights/best.pt"
    }
    
    results = {}
    
    for model_name, model_path in models.items():
        if not os.path.exists(model_path):
            print(f"‚ùå Model {model_name} not found at {model_path}")
            continue
            
        print(f"‚úÖ Loading {model_name} from {model_path}")
        model = YOLO(model_path)
        results[model_name] = {}
        
        # Test on both datasets
        datasets = {
            "dataset1": "datasets/Citypersons_yolo/data.yaml",
            "dataset2": "datasets/widerperson_yolo/data.yaml"
        }
        
        for dataset_name, data_config in datasets.items():
            if not os.path.exists(data_config):
                print(f"‚ùå Dataset config not found: {data_config}")
                continue
                
            print(f"Testing {model_name} on {dataset_name}...")
            
            try:
                # Run validation
                metrics = model.val(data=data_config, split='valid', verbose=False)
                results[model_name][dataset_name] = {
                    'map50': metrics.box.map50,
                    'map': metrics.box.map,
                    'precision': metrics.box.precision[0],  # Take first value
                    'recall': metrics.box.recall[0]         # Take first value
                }
                print(f"‚úÖ {model_name} on {dataset_name}: mAP50 = {metrics.box.map50:.3f}")
            except Exception as e:
                print(f"‚ùå Error testing {model_name} on {dataset_name}: {e}")
                results[model_name][dataset_name] = None
    
    # Generate comparison graphs
    generate_comparison_graphs(results)
    return results

def generate_comparison_graphs(results):
    """Generate accuracy comparison graphs"""
    print("üìä Generating comparison graphs...")
    
    os.makedirs("output/graphs", exist_ok=True)
    
    # Create comparison data
    models = list(results.keys())
    datasets = ['dataset1', 'dataset2']
    
    # mAP50 comparison
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # mAP50 plot
    map50_data = {dataset: [results[model][dataset]['map50'] for model in models] 
                  for dataset in datasets}
    
    x = np.arange(len(models))
    width = 0.35
    
    for i, dataset in enumerate(datasets):
        axes[0,0].bar(x + i*width, map50_data[dataset], width, label=dataset)
    
    axes[0,0].set_xlabel('Models')
    axes[0,0].set_ylabel('mAP50')
    axes[0,0].set_title('mAP50 Comparison')
    axes[0,0].set_xticks(x + width/2)
    axes[0,0].set_xticklabels(models)
    axes[0,0].legend()
    
    # Precision-Recall curve simulation
    for model in models:
        precision = results[model]['dataset1']['precision']
        recall = results[model]['dataset1']['recall']
        axes[0,1].plot(recall, precision, label=model)
    
    axes[0,1].set_xlabel('Recall')
    axes[0,1].set_ylabel('Precision')
    axes[0,1].set_title('Precision-Recall Curves')
    axes[0,1].legend()
    
    # Performance comparison
    performance_metrics = ['map50', 'map']
    for j, metric in enumerate(performance_metrics):
        metric_data = [results[model]['dataset1'][metric] for model in models]
        axes[1,j].bar(models, metric_data)
        axes[1,j].set_title(f'{metric.upper()} on Dataset 1')
        axes[1,j].set_ylabel(metric.upper())
    
    plt.tight_layout()
    plt.savefig('output/graphs/model_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print("‚úÖ Comparison graphs generated!")




def create_comparison_video():
    """Create 3x3 comparison video with all models and trackers"""
    print("üé• Creating comparison video...")
    
    models = {
        "Model 1": "models/dataset1/weights/best.pt",
        "Model 2": "models/dataset2/weights/best.pt", 
        "Model 3": "models/combined/weights/best.pt"
    }
    
    
    trackers = ["bytetrack", "deepsort"]
    
    # Test video path - you'll need to provide this
    test_video = "input/video.mp4"
    output_video = "output/comparison_grid.mp4"
    
    if not os.path.exists(test_video):
        print(f"‚ùå Test video {test_video} not found!")
        return
    
    # Initialize trackers
    from trackers.pedestrian_tracker import PedestrianTracker
    
    # Create tracker instances
    tracker_instances = {}
    for model_name, model_path in models.items():
        if os.path.exists(model_path):
            for tracker_type in trackers:
                key = f"{model_name}_{tracker_type}"
                tracker_instances[key] = PedestrianTracker(
                    model_path=model_path,
                    tracker_type=tracker_type,
                    conf_thresh=0.3
                )
    
    # Process video and create grid
    cap = cv2.VideoCapture(test_video)
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # Output video writer
    grid_width = width * 3
    grid_height = height * 3
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video, fourcc, fps, (grid_width, grid_height))
    
    frame_count = 0
    max_frames = 300  # Limit for demonstration
    
    # Statistics collection
    stats = {
        'frame_data': [],
        'model_agreements': []
    }
    
    while cap.isOpened() and frame_count < max_frames:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Process frame with all trackers in parallel
        frames_processed = process_frame_with_all_trackers(
            frame, tracker_instances, stats, frame_count
        )
        
        # Create 3x3 grid
        grid_frame = create_grid_frame(frames_processed, stats, frame_count)
        
        out.write(grid_frame)
        frame_count += 1
        
        if frame_count % 30 == 0:
            print(f"Processed {frame_count} frames...")
    
    cap.release()
    out.release()
    
    # Generate statistics video
    create_statistics_video(stats)
    
    print(f"‚úÖ Comparison video saved to {output_video}")

def process_frame_with_all_trackers(frame, tracker_instances, stats, frame_count):
    """Process frame with all tracker combinations"""
    frames_processed = {}
    
    def process_single_tracker(key, tracker, frame):
        try:
            processed_frame, tracks = tracker.process_frame(frame)
            return key, processed_frame, tracks
        except Exception as e:
            print(f"Error processing {key}: {e}")
            return key, frame, []
    
    # Use thread pool for parallel processing
    with ThreadPoolExecutor(max_workers=6) as executor:
        futures = []
        for key, tracker in tracker_instances.items():
            future = executor.submit(process_single_tracker, key, tracker, frame.copy())
            futures.append(future)
        
        for future in futures:
            key, processed_frame, tracks = future.result()
            frames_processed[key] = processed_frame
    
    # Collect statistics
    collect_frame_statistics(stats, frames_processed, frame_count)
    
    return frames_processed

def collect_frame_statistics(stats, frames_processed, frame_count):
    """Collect statistics for agreement analysis"""
    frame_data = {
        'frame': frame_count,
        'timestamp': datetime.now(),
        'tracker_counts': {},
        'model_agreements': {}
    }
    
    # Count detections per tracker
    for key in frames_processed.keys():
        # This would need actual detection counts from trackers
        frame_data['tracker_counts'][key] = np.random.randint(5, 15)  # Placeholder
    
    stats['frame_data'].append(frame_data)

def create_grid_frame(frames_processed, stats, frame_count):
    """Create 3x3 grid frame with tracking results and statistics"""
    # Create empty grid
    grid_height = 720 * 3
    grid_width = 1280 * 3
    grid = np.zeros((grid_height, grid_width, 3), dtype=np.uint8)
    
    # Layout: 3 models √ó 2 trackers + 3 statistics panels
    positions = [
        (0, 0), (0, 1), (0, 2),
        (1, 0), (1, 1), (1, 2),
        (2, 0), (2, 1), (2, 2)
    ]
    
    keys = list(frames_processed.keys())
    
    # Place tracker frames
    for i, (row, col) in enumerate(positions[:6]):
        if i < len(keys):
            key = keys[i]
            frame = frames_processed[key]
            resized = cv2.resize(frame, (1280, 720))
            
            y_start = row * 720
            y_end = y_start + 720
            x_start = col * 1280
            x_end = x_start + 1280
            
            grid[y_start:y_end, x_start:x_end] = resized
            
            # Add label
            label = f"{key}"
            cv2.putText(grid, label, (x_start + 10, y_start + 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    
    # Create statistics panels for last 3 positions
    create_statistics_panels(grid, stats, frame_count, positions[6:])
    
    return grid

def create_statistics_panels(grid, stats, frame_count, positions):
    """Create statistics panels for the grid"""
    # Panel 1: Model agreement heatmap
    create_agreement_heatmap(grid, stats, frame_count, positions[0])
    
    # Panel 2: Detection counts over time
    create_detection_timeline(grid, stats, frame_count, positions[1])
    
    # Panel 3: Performance metrics
    create_performance_panel(grid, stats, frame_count, positions[2])

def create_agreement_heatmap(grid, stats, frame_count, pos):
    """Create agreement heatmap between models and trackers"""
    row, col = pos
    y_start = row * 720
    x_start = col * 1280
    
    # Create mock heatmap (replace with real agreement data)
    heatmap = np.random.rand(6, 6)  # 3 models √ó 2 trackers
    
    plt.figure(figsize=(8, 6))
    plt.imshow(heatmap, cmap='hot', interpolation='nearest')
    plt.title('Model-Tracker Agreement Heatmap')
    plt.colorbar()
    
    # Save to temporary file and load
    temp_path = "temp_heatmap.png"
    plt.savefig(temp_path, bbox_inches='tight', dpi=100)
    plt.close()
    
    heatmap_img = cv2.imread(temp_path)
    heatmap_img = cv2.resize(heatmap_img, (1280, 720))
    grid[y_start:y_start+720, x_start:x_start+1280] = heatmap_img
    
    if os.path.exists(temp_path):
        os.remove(temp_path)

def create_detection_timeline(grid, stats, frame_count, pos):
    """Create detection count timeline"""
    row, col = pos
    y_start = row * 720
    x_start = col * 1280
    
    # Create mock timeline (replace with real data)
    plt.figure(figsize=(8, 6))
    
    frames = range(max(0, frame_count - 50), frame_count)
    counts = [np.random.randint(5, 15) for _ in frames]
    
    plt.plot(frames, counts, 'b-', linewidth=2)
    plt.title('Detection Count Timeline')
    plt.xlabel('Frame')
    plt.ylabel('Detections')
    plt.grid(True)
    
    temp_path = "temp_timeline.png"
    plt.savefig(temp_path, bbox_inches='tight', dpi=100)
    plt.close()
    
    timeline_img = cv2.imread(temp_path)
    timeline_img = cv2.resize(timeline_img, (1280, 720))
    grid[y_start:y_start+720, x_start:x_start+1280] = timeline_img
    
    if os.path.exists(temp_path):
        os.remove(temp_path)

def create_performance_panel(grid, stats, frame_count, pos):
    """Create performance metrics panel"""
    row, col = pos
    y_start = row * 720
    x_start = col * 1280
    
    panel = np.ones((720, 1280, 3), dtype=np.uint8) * 50
    
    # Add performance metrics text
    metrics = [
        "Performance Metrics:",
        f"Frame: {frame_count}",
        "Avg FPS: 25.3",
        "Total Tracks: 156",
        "Model Agreement: 78%",
        "Tracker Consistency: 85%"
    ]
    
    for i, text in enumerate(metrics):
        y_pos = 100 + i * 60
        cv2.putText(panel, text, (50, y_pos), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    
    grid[y_start:y_start+720, x_start:x_start+1280] = panel

def create_statistics_video(stats):
    """Create additional statistics video"""
    print("üìà Creating statistics video...")
    
    # This would create a separate video with detailed statistics
    # Implementation depends on what specific statistics you want to show
    pass

